{% set name = "deepspeed" %}
{% set version = "0.17.4" %}
{% set number = 0 %}

{% set torch_proc_type = "cuda" if cuda_compiler_version != "None" else "cpu" %}

{% if cuda_compiler_version in (None, "None", True, False) %}
  {% set cuda_major = 0 %}
  {% set build_number = number %}
  {% set build_string = 'cpu_' %}
{% else %}
  {% set cuda_major = environ.get("cuda_compiler_version", "11.8").split(".")[0] | int %}
  # Prioritize GPU builds
  {% set build_number = number + 200 %}
  {% set build_string = 'cuda' ~ (cuda_compiler_version | replace('.', '')) %}
{% endif %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: d8254ce983734d14a23b8b73937338de82475b146a1bbcdf5fb4e30295e0ddb7

build:
  number: {{ build_number }}
  string: {{ build_string }}py{{ py }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
  skip: true  # [win]

requirements:
  # NOTE(hadim): pytorch is only needed during the build in reqs.build and reqs.host when the ops are being built which
  # is only possible when CUDA is available. To prevent creating too many builds for pytorch-cpu we remove the pytorch
  # requirements when CUDA is not available.

  build:
    - cross-python_{{ target_platform }}               # [build_platform != target_platform]
    - pip
    - python                                           # [build_platform != target_platform]
    - pytorch                                          # [(build_platform != target_platform) and cuda_compiler_version not in (undefined, 'None')]
    - setuptools
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}                           # [cuda_compiler_version not in (undefined, 'None')]
    - {{ stdlib("c") }}
    {% if cuda_major >= 12 %}
    - cuda-profiler-api                                # [build_platform != target_platform]
    - libcublas-dev                                    # [build_platform != target_platform]
    - libcurand-dev                                    # [build_platform != target_platform]
    - libcusolver-dev                                  # [build_platform != target_platform]
    - libcusparse-dev                                  # [build_platform != target_platform]
    {% endif %}
  host:
    - git
    # For the `async_io` op
    - libaio                                           # [linux]
    - oneccl-devel                                     # [cuda_compiler_version not in (undefined, 'None')]
    - pip
    - py-cpuinfo
    - python
    # Leaving two dependencies helps rerender correctly
    # The first gets filled in by the global pinnings
    # The second gets the processor type
    - pytorch                                          # [cuda_compiler_version not in (undefined, 'None')]
    - pytorch * {{ torch_proc_type }}*                 # [cuda_compiler_version not in (undefined, 'None')]
    - setuptools
    {% if cuda_major >= 12 %}
    - cuda-profiler-api
    - libcublas-dev
    - libcurand-dev
    - libcusolver-dev
    - libcusparse-dev
    {% endif %}
  run:
    - ninja
    - einops
    - hjson-py
    - msgpack-python
    # NOTE(hadim): coming at https://github.com/conda-forge/staged-recipes/pull/19098
    # - ninja-python
    - numpy
    - nvidia-ml-py                                     # [cuda_compiler_version not in (undefined, 'None')]
    - packaging >=20.0
    - psutil
    - py-cpuinfo
    - pydantic >=2.0.0
    - python
    - pytorch                                          # [cuda_compiler_version in (undefined, 'None')]
    - setuptools
    - tqdm
  run_constrained:
    # 2022/02/05 hmaarrfk
    # While conda packaging seems to allow us to specify
    # constraints on the same package in different lines
    # the resulting package doesn't have the ability to
    # be specified in multiples lines
    # This makes it tricky to use run_exports
    # we add the GPU constraint in the run_constrained
    # to allow us to have "two" constraints on the
    # running package
    - pytorch * {{ torch_proc_type }}*               # [cuda_compiler_version not in (undefined, 'None')]

test:
  imports:
    - deepspeed
  commands:
    # NOTE(hadim): need ninja-python for the pip check to pass
    # - pip check
    - ds_report
    - deepspeed --help
  requires:
    - pip

about:
  home: http://deepspeed.ai
  summary: DeepSpeed library
  dev_url: https://github.com/deepspeedai/DeepSpeed
  license: Apache-2.0
  license_file: LICENSE

extra:
  recipe-maintainers:
    - weiji14
    - loadams
